# coding:utf-8
from __future__ import division
import re
from collections import *
import os
import pandas as pd

from sklearn import feature_extraction
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
transformer = TfidfTransformer()
vectorizer = CountVectorizer()
ops_corus = []

def getOpcodeSequence(filename):
    opcode_seq = []
    p = re.compile(r'\s*([a-uA-U]+)([\s|\-|\/]{1})')
    with open(filename) as f:
        for line in f:
            #if line.startswith(".text"):
                m = re.findall(p,line)
                if m:
                    opc = m[0][0]
                    #if opc != "align":
                    opcode_seq.append(opc)
    return opcode_seq

# def train_opcode_lm(ops, order=4):
#     lm = defaultdict(Counter)
#     prefix = ["~"] * order
#     prefix.extend(ops)
#     data = prefix
#     for i in xrange(len(data)-order):
#         history, char = tuple(data[i:i+order]), data[i+order]
#         lm[history][char]+=1
#     def normalize(counter):
#         s = float(sum(counter.values()))
#         return [(c,cnt/s) for c,cnt in counter.iteritems()]
#     outlm = {hist:chars for hist, chars in lm.iteritems()}
#     return outlm
def getOpcodeNgram(ops, n=3):
    opngramlist = [''.join(ops[i:i+n]) for i in range(len(ops)-n)]
    opngram = Counter(opngramlist)
    return opngram

basepath = 'E:/sample/dataSample_myself/subtrain/'
map3gram = defaultdict(Counter)
subtrain = pd.read_csv('subtrainLabels_test.csv')
count = 1
for sid in subtrain.Id:
    print "counting the 3-gram of the {0} file...".format(str(count))
    count += 1
    filename = basepath + sid + ".smali"
    ops = getOpcodeSequence(filename)
    op3gram = getOpcodeNgram(ops)
    ops_corus.append(' '.join(op3gram))
    map3gram[sid] = op3gram
# compute TFIDF
ops_count = vectorizer.fit_transform(ops_corus)
tfidf = transformer.fit_transform(ops_count)
word = vectorizer.get_feature_names()
weight = tfidf.toarray()
cc = Counter([])
for d in map3gram.values():
    cc += d
selectedfeatures = {}
tc = 0
#select top 50 by DF
for k,v in cc.most_common(50):
    selectedfeatures[k] = v
    print (k,v)
    tc += 1
dataframelist = []
i = 0
for fid,op3gram in map3gram.iteritems():
    standard = {}
    standard["Id"] = fid
    for feature in selectedfeatures:
            for j in range(len(word)):
                if feature == word[j]:
                    standard[feature] = weight[i][j]
    dataframelist.append(standard)
    i += 1
df = pd.DataFrame(dataframelist)
df.to_csv("TFIDF_top50_3gramfeature_test.csv",index=False)
